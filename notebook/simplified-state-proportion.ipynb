{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "09011e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import system modules\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/Users/Volkan/Repos/somnotate-vlkuzun/src/somnotate_pipeline') # Adjust the path as necessary to your somnotate_pipeline directory\n",
    "\n",
    "# Import required libraries for the pipeline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import pyedflib\n",
    "\n",
    "# Import functions from pipeline modules\n",
    "from mat_to_csv import mat_to_csv\n",
    "from make_path_sheet import make_train_and_test_sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c0e3e",
   "metadata": {},
   "source": [
    "# Somnotate Pipeline Notebook\n",
    "\n",
    "This notebook provides a streamlined interface for running the somnotate pipeline:\n",
    "1. Convert MAT files to CSV format\n",
    "2. Generate EDF and Visbrain format files for visualization and analysis\n",
    "3. Generate path sheet for organizing files\n",
    "\n",
    "Run each section in sequence, providing the requested inputs when prompted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14587a9b",
   "metadata": {},
   "source": [
    "# Common Input Parameters\n",
    "\n",
    "To make the workflow more efficient, we'll collect all common input parameters at the beginning and use them throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fdac617a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the common parameters that will be used throughout the pipeline:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Enter subject and recording information (format: comma-separated values without spaces)\n",
      "\n",
      "Enter subject and recording information (format: comma-separated values without spaces)\n",
      "\n",
      "Input Summary:\n",
      "Dataset type: to_score\n",
      "Base directory: /Volumes/harris/volkan/somnotate-vlkuzun-testing\n",
      "Sampling rate: 512.0 Hz\n",
      "Sleep stage resolution: 10 seconds\n",
      "Mouse IDs: sub-015\n",
      "Session IDs: ses-01\n",
      "Recording IDs: recording-01\n",
      "Extra info: time-0-20h\n",
      "CSV output directory: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_csv_files\n",
      "\n",
      "Input Summary:\n",
      "Dataset type: to_score\n",
      "Base directory: /Volumes/harris/volkan/somnotate-vlkuzun-testing\n",
      "Sampling rate: 512.0 Hz\n",
      "Sleep stage resolution: 10 seconds\n",
      "Mouse IDs: sub-015\n",
      "Session IDs: ses-01\n",
      "Recording IDs: recording-01\n",
      "Extra info: time-0-20h\n",
      "CSV output directory: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_csv_files\n"
     ]
    }
   ],
   "source": [
    "# Collect common input parameters that will be reused throughout the notebook\n",
    "# -----------------------------------------------------------------------------------\n",
    "print(\"Enter the common parameters that will be used throughout the pipeline:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Dataset type\n",
    "dataset_type = input(\"Enter dataset type ('train', 'test', or 'to_score'): \")\n",
    "\n",
    "# Base directory\n",
    "base_directory = input(f\"Enter the base somnotate directory path, without quotes (e.g., Z:/somnotate): \")\n",
    "\n",
    "# Sampling rate\n",
    "sampling_rate = float(input(\"Enter the sampling rate in Hz (e.g., 512.0): \"))\n",
    "\n",
    "# Sleep stage resolution\n",
    "sleep_stage_resolution = int(input(\"Enter the sleep stage resolution in seconds (e.g., 10): \"))\n",
    "\n",
    "# Mouse, session, recording information\n",
    "print(\"\\nEnter subject and recording information (format: comma-separated values without spaces)\")\n",
    "mouse_ids = input(\"Enter mouse IDs (e.g., sub-001,sub-002): \").split(',')\n",
    "sessions = input(\"Enter session IDs (e.g., ses-01,ses-02): \").split(',')\n",
    "recordings = input(\"Enter recording IDs (e.g., recording-01,recording-02): \").split(',')\n",
    "extra_info = input(\"Enter any extra details about the recording (leave blank if not applicable): \").strip()\n",
    "\n",
    "# Define derived paths for reuse\n",
    "output_directory_path = os.path.join(base_directory, f\"{dataset_type}_set\", f\"{dataset_type}_csv_files\")\n",
    "\n",
    "# Print summary of all inputs\n",
    "print(\"\\nInput Summary:\")\n",
    "print(f\"Dataset type: {dataset_type}\")\n",
    "print(f\"Base directory: {base_directory}\")\n",
    "print(f\"Sampling rate: {sampling_rate} Hz\")\n",
    "print(f\"Sleep stage resolution: {sleep_stage_resolution} seconds\")\n",
    "print(f\"Mouse IDs: {', '.join(mouse_ids)}\")\n",
    "print(f\"Session IDs: {', '.join(sessions)}\")\n",
    "print(f\"Recording IDs: {', '.join(recordings)}\")\n",
    "print(f\"Extra info: {extra_info if extra_info else 'None'}\")\n",
    "print(f\"CSV output directory: {output_directory_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f2f2adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation of the generate_edf_and_visbrain_formats function directly in the notebook\n",
    "def generate_edf_and_visbrain_formats(mouse_ids, sessions, recordings, extra_info, test_train_or_to_score, base_directory, sample_frequency):\n",
    "    '''\n",
    "    Generate EDF and Visbrain stage duration format files from CSV files, respectively for EEG and EMG data and sleep stage annotations.\n",
    "    \n",
    "    Inputs:\n",
    "    mouse_ids: list of str, mouse IDs\n",
    "    sessions: list of str, session IDs\n",
    "    recordings: list of str, recording IDs\n",
    "    extra_info: str, additional information to include in the output filenames for differentiation (optional)\n",
    "    test_train_or_to_score: str, 'test', 'train' or 'to_score' to specify which dataset to process\n",
    "    base_directory: str, path to the base directory where the CSV files are stored and where the output EDF and annotations files should be saved\n",
    "    sample_frequency: float, the sampling frequency in Hz for the data\n",
    "\n",
    "    Outputs:\n",
    "    EDF files and annotations in Visbrain stage duration format are saved in the 'edfs' and '{test_train_or_to_score}_manual_annotation' directories, respectively.\n",
    "    '''\n",
    "\n",
    "    # Define output directories\n",
    "    csv_input_dir = os.path.join(base_directory, f\"{test_train_or_to_score}_set/{test_train_or_to_score}_csv_files\")\n",
    "    edf_output_dir = os.path.join(base_directory, f\"{test_train_or_to_score}_set\", 'edfs')\n",
    "    annotations_output_dir = os.path.join(base_directory, f\"{test_train_or_to_score}_set\", f\"{test_train_or_to_score}_manual_annotation\")\n",
    "    \n",
    "    if not os.path.exists(edf_output_dir):\n",
    "        os.makedirs(edf_output_dir)\n",
    "    if not os.path.exists(annotations_output_dir):\n",
    "        os.makedirs(annotations_output_dir)\n",
    "\n",
    "    # Process each CSV file and generate output\n",
    "    for mouse_id in mouse_ids:\n",
    "        for session in sessions:\n",
    "            for recording in recordings:\n",
    "                # Prepare the base filename for the CSV file\n",
    "                base_filename = f\"{mouse_id}_{session}_{recording}\"\n",
    "                if extra_info:\n",
    "                    csv_file = os.path.join(csv_input_dir, f\"{base_filename}_{extra_info}.csv\")\n",
    "                else:\n",
    "                    csv_file = os.path.join(csv_input_dir, f\"{base_filename}.csv\")\n",
    "                \n",
    "                # Prepare the base filename for EDF and Visbrain files\n",
    "                if extra_info:\n",
    "                    edf_file = os.path.join(edf_output_dir, f\"output_{base_filename}_{extra_info}.edf\")\n",
    "                    visbrain_file = os.path.join(annotations_output_dir, f\"annotations_visbrain_{base_filename}_{extra_info}.txt\")\n",
    "                else:\n",
    "                    edf_file = os.path.join(edf_output_dir, f\"output_{base_filename}.edf\")\n",
    "                    visbrain_file = os.path.join(annotations_output_dir, f\"annotations_visbrain_{base_filename}.txt\")\n",
    "\n",
    "                if not os.path.isfile(csv_file):\n",
    "                    print(f\"File not found: {csv_file}\")\n",
    "                    continue\n",
    "                if os.path.exists(edf_file):\n",
    "                    print(f\"EDF file already exists: {edf_file}\")\n",
    "                    continue\n",
    "            \n",
    "                print(f\"Processing file: {csv_file}\")\n",
    "                df = pd.read_csv(csv_file)\n",
    "\n",
    "                # Extract EEG and EMG data\n",
    "                eeg1_data = df[\"EEG1\"].to_numpy()\n",
    "                eeg2_data = df[\"EEG2\"].to_numpy()\n",
    "                emg_data = df[\"EMG\"].to_numpy()\n",
    "\n",
    "                # Combine all data\n",
    "                all_data = np.array([eeg1_data, eeg2_data, emg_data])\n",
    "\n",
    "                # Create an EDF file\n",
    "                f = pyedflib.EdfWriter(edf_file, len(all_data), file_type=pyedflib.FILETYPE_EDFPLUS)\n",
    "\n",
    "                # Define EDF header information\n",
    "                labels = [\"EEG1\", \"EEG2\", \"EMG\"]\n",
    "                for i, label in enumerate(labels):\n",
    "                    signal_info = {\n",
    "                        'label': label,\n",
    "                        'dimension': 'uV',\n",
    "                        'sample_frequency': sample_frequency,\n",
    "                        'physical_min': np.min(all_data[i]),\n",
    "                        'physical_max': np.max(all_data[i]),\n",
    "                        'digital_min': -32768,\n",
    "                        'digital_max': 32767,\n",
    "                        'transducer': '',\n",
    "                        'prefilter': ''\n",
    "                    }\n",
    "                    f.setSignalHeader(i, signal_info)\n",
    "\n",
    "                # Write EEG and EMG data to the EDF file\n",
    "                f.writeSamples(all_data)\n",
    "                f.close()\n",
    "\n",
    "                # Prepare annotations in Visbrain stage duration format\n",
    "                annotations = [(0, 10, \"Undefined\")]\n",
    "                current_stage = None\n",
    "                start_time = 10 / sample_frequency\n",
    "\n",
    "                for i, label in enumerate(df[\"sleepStage\"]):\n",
    "                    current_time = i / sample_frequency\n",
    "                    if label != current_stage:\n",
    "                        if current_stage is not None:\n",
    "                            annotations.append((start_time, current_time, current_stage))\n",
    "                        current_stage = label\n",
    "                        start_time = current_time\n",
    "                annotations.append((start_time, len(df) / sample_frequency, current_stage))\n",
    "\n",
    "                # Write annotations to a text file\n",
    "                last_time_value = annotations[-1][1]\n",
    "                with open(visbrain_file, \"w\") as f:\n",
    "                    f.write(f\"*Duration_sec    {last_time_value}\\n\")\n",
    "                    f.write(\"*Datafile\\tUnspecified\\n\")\n",
    "                    for start, end, stage in annotations:\n",
    "                        stage_label = {1: \"awake\", 2: \"non-REM\", 3: \"REM\", 4: 'ambiguous', 5: 'doubt'}.get(stage, \"Undefined\")\n",
    "                        f.write(f\"{stage_label}    {end}\\n\")\n",
    "\n",
    "                print(f\"EDF file and annotations created successfully for {mouse_id}, {session}, {recording} with extra info '{extra_info}'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96fa57d",
   "metadata": {},
   "source": [
    "# MAT to CSV Conversion\n",
    "\n",
    "The first step in the pipeline is to convert MAT files (MATLAB format) to CSV format for easier manipulation in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fba2d7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: MAT to CSV Conversion\n",
      "-----------------------------\n",
      "Using dataset type: to_score\n",
      "Using output directory: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_csv_files\n",
      "Using sampling rate: 512.0 Hz\n",
      "Using sleep stage resolution: 10 seconds\n",
      "\n",
      "Enter the full paths of .mat files to convert (press Enter on an empty line to finish):\n",
      "\n",
      "Files to process: 1\n",
      "  1. /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_mat_files/sub-015_ses-01_recording-01_time-0-20h.mat\n",
      "\n",
      "Files to process: 1\n",
      "  1. /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_mat_files/sub-015_ses-01_recording-01_time-0-20h.mat\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: MAT to CSV Conversion\n",
    "# ---------------------------\n",
    "print(\"STEP 1: MAT to CSV Conversion\")\n",
    "print(\"-----------------------------\")\n",
    "\n",
    "# We'll use the input parameters collected at the beginning\n",
    "print(f\"Using dataset type: {dataset_type}\")\n",
    "print(f\"Using output directory: {output_directory_path}\")\n",
    "print(f\"Using sampling rate: {sampling_rate} Hz\")\n",
    "print(f\"Using sleep stage resolution: {sleep_stage_resolution} seconds\")\n",
    "\n",
    "# Allow user to enter file paths one by one\n",
    "file_paths = []\n",
    "print(\"\\nEnter the full paths of .mat files to convert (press Enter on an empty line to finish):\")\n",
    "while True:\n",
    "    file_path = input(\"Enter file path: \")\n",
    "    if file_path == \"\":\n",
    "        break\n",
    "    if os.path.isfile(file_path) and file_path.endswith('.mat'):\n",
    "        file_paths.append(file_path)\n",
    "    else:\n",
    "        print(\"Invalid file path. Please enter a valid .mat file path.\")\n",
    "\n",
    "# Print summary of files to process\n",
    "print(f\"\\nFiles to process: {len(file_paths)}\")\n",
    "for i, path in enumerate(file_paths):\n",
    "    print(f\"  {i+1}. {path}\")\n",
    "\n",
    "# Confirm before proceeding\n",
    "proceed = input(\"\\nProceed with MAT to CSV conversion? (y/n): \").strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dbf59e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting MAT to CSV conversion process...\n",
      "Processing file: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_mat_files/sub-015_ses-01_recording-01_time-0-20h.mat\n",
      "EEG1 data extracted successfully.\n",
      "EEG2 data extracted successfully.\n",
      "EMG data extracted successfully.\n",
      "Length of upsampled sleep stages (5120) does not match length of EEG data (37319680)\n",
      "EEG1 data extracted successfully.\n",
      "EEG2 data extracted successfully.\n",
      "EMG data extracted successfully.\n",
      "Length of upsampled sleep stages (5120) does not match length of EEG data (37319680)\n",
      "Saved CSV to: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_csv_files/sub-015_ses-01_recording-01_time-0-20h.csv\n",
      "\n",
      "MAT to CSV conversion completed successfully!\n",
      "CSV files are saved to: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_csv_files\n",
      "\n",
      "Created 1 CSV files:\n",
      "  1. sub-015_ses-01_recording-01_time-0-20h.csv\n",
      "Saved CSV to: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_csv_files/sub-015_ses-01_recording-01_time-0-20h.csv\n",
      "\n",
      "MAT to CSV conversion completed successfully!\n",
      "CSV files are saved to: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_csv_files\n",
      "\n",
      "Created 1 CSV files:\n",
      "  1. sub-015_ses-01_recording-01_time-0-20h.csv\n"
     ]
    }
   ],
   "source": [
    "# Execute the MAT to CSV conversion if inputs are valid\n",
    "if proceed == 'y' and file_paths and output_directory_path:\n",
    "    try:\n",
    "        print(\"Starting MAT to CSV conversion process...\")\n",
    "        \n",
    "        # Create the output directory if it doesn't exist\n",
    "        if not os.path.exists(output_directory_path):\n",
    "            os.makedirs(output_directory_path)\n",
    "            print(f\"Created output directory: {output_directory_path}\")\n",
    "        \n",
    "        # Execute the conversion\n",
    "        mat_to_csv(file_paths, output_directory_path, sampling_rate, sleep_stage_resolution)\n",
    "        \n",
    "        print(\"\\nMAT to CSV conversion completed successfully!\")\n",
    "        print(f\"CSV files are saved to: {output_directory_path}\")\n",
    "        \n",
    "        # List the created output files\n",
    "        output_files = [f for f in os.listdir(output_directory_path) if f.endswith('.csv')]\n",
    "        print(f\"\\nCreated {len(output_files)} CSV files:\")\n",
    "        for i, file in enumerate(output_files):\n",
    "            print(f\"  {i+1}. {file}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during conversion: {str(e)}\")\n",
    "else:\n",
    "    print(\"MAT to CSV conversion cancelled or missing required inputs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ad62ad",
   "metadata": {},
   "source": [
    "# EDF and Visbrain Format Generation\n",
    "\n",
    "After converting MAT files to CSV, the next step is to generate EDF files for the EEG/EMG data and Visbrain format files for the sleep stage annotations. This allows for visualization and further analysis of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9d3fd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Generate EDF and Visbrain Format Files\n",
      "-----------------------------------------\n",
      "Using dataset type: to_score\n",
      "Using base directory: /Volumes/harris/volkan/somnotate-vlkuzun-testing\n",
      "Using sampling rate: 512.0 Hz\n",
      "Using mouse IDs: sub-015\n",
      "Using session IDs: ses-01\n",
      "Using recording IDs: recording-01\n",
      "Using extra info: time-0-20h\n",
      "\n",
      "EDF files will be saved to: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/edfs\n",
      "Annotation files will be saved to: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_manual_annotation\n"
     ]
    }
   ],
   "source": [
    "# STEP 2: Generate EDF and Visbrain Format Files\n",
    "# ----------------------------------------------\n",
    "print(\"STEP 2: Generate EDF and Visbrain Format Files\")\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "# Use the parameters collected at the beginning\n",
    "print(f\"Using dataset type: {dataset_type}\")\n",
    "print(f\"Using base directory: {base_directory}\")\n",
    "print(f\"Using sampling rate: {sampling_rate} Hz\")\n",
    "print(f\"Using mouse IDs: {', '.join(mouse_ids)}\")\n",
    "print(f\"Using session IDs: {', '.join(sessions)}\")\n",
    "print(f\"Using recording IDs: {', '.join(recordings)}\")\n",
    "print(f\"Using extra info: {extra_info if extra_info else 'None'}\")\n",
    "\n",
    "# Calculate expected output paths for verification\n",
    "edf_output_dir = os.path.join(base_directory, f\"{dataset_type}_set\", 'edfs')\n",
    "annotations_output_dir = os.path.join(base_directory, f\"{dataset_type}_set\", f\"{dataset_type}_manual_annotation\")\n",
    "\n",
    "print(f\"\\nEDF files will be saved to: {edf_output_dir}\")\n",
    "print(f\"Annotation files will be saved to: {annotations_output_dir}\")\n",
    "\n",
    "# Confirm before proceeding\n",
    "proceed = input(\"\\nProceed with EDF and Visbrain format generation? (y/n): \").strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0d7ae2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting EDF and Visbrain format generation...\n",
      "Processing file: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_csv_files/sub-015_ses-01_recording-01_time-0-20h.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Volkan/miniconda3/envs/somnotate-vlkuzun/lib/python3.11/site-packages/pyedflib/edfwriter.py:133: UserWarning: Physical minimum for channel 0 (EEG1) is -480.70989990234375, which has 19 chars, however, EDF+ can only save 8 chars, will be truncated to -480.709, some loss of precision is to be expected\n",
      "  warnings.warn('Physical minimum for channel {} ({}) is {}, which has {} chars, '\n",
      "/Users/Volkan/miniconda3/envs/somnotate-vlkuzun/lib/python3.11/site-packages/pyedflib/edfwriter.py:140: UserWarning: Physical maximum for channel 0 (EEG1) is 480.4759826660156, which has 17 chars, however, EDF+ can only save 8 chars, will be truncated to 480.4759, some loss of precision is to be expected.\n",
      "  warnings.warn('Physical maximum for channel {} ({}) is {}, which has {} chars, '\n",
      "/Users/Volkan/miniconda3/envs/somnotate-vlkuzun/lib/python3.11/site-packages/pyedflib/edfwriter.py:133: UserWarning: Physical minimum for channel 1 (EEG2) is -480.2402648925781, which has 18 chars, however, EDF+ can only save 8 chars, will be truncated to -480.240, some loss of precision is to be expected\n",
      "  warnings.warn('Physical minimum for channel {} ({}) is {}, which has {} chars, '\n",
      "/Users/Volkan/miniconda3/envs/somnotate-vlkuzun/lib/python3.11/site-packages/pyedflib/edfwriter.py:140: UserWarning: Physical maximum for channel 1 (EEG2) is 480.4759826660156, which has 17 chars, however, EDF+ can only save 8 chars, will be truncated to 480.4759, some loss of precision is to be expected.\n",
      "  warnings.warn('Physical maximum for channel {} ({}) is {}, which has {} chars, '\n",
      "/Users/Volkan/miniconda3/envs/somnotate-vlkuzun/lib/python3.11/site-packages/pyedflib/edfwriter.py:133: UserWarning: Physical minimum for channel 2 (EMG) is -480.47509765625, which has 16 chars, however, EDF+ can only save 8 chars, will be truncated to -480.475, some loss of precision is to be expected\n",
      "  warnings.warn('Physical minimum for channel {} ({}) is {}, which has {} chars, '\n",
      "/Users/Volkan/miniconda3/envs/somnotate-vlkuzun/lib/python3.11/site-packages/pyedflib/edfwriter.py:140: UserWarning: Physical maximum for channel 2 (EMG) is 480.2411804199219, which has 17 chars, however, EDF+ can only save 8 chars, will be truncated to 480.2411, some loss of precision is to be expected.\n",
      "  warnings.warn('Physical maximum for channel {} ({}) is {}, which has {} chars, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF file and annotations created successfully for sub-015, ses-01, recording-01 with extra info 'time-0-20h'.\n",
      "\n",
      "EDF and Visbrain format generation completed!\n",
      "EDF files saved to: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/edfs\n",
      "Visbrain annotations saved to: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_manual_annotation\n"
     ]
    }
   ],
   "source": [
    "# Execute the EDF and Visbrain format generation\n",
    "if proceed == 'y':\n",
    "    try:\n",
    "        print(\"Starting EDF and Visbrain format generation...\")\n",
    "        \n",
    "        # Create directories if they don't exist\n",
    "        if not os.path.exists(edf_output_dir):\n",
    "            os.makedirs(edf_output_dir)\n",
    "            print(f\"Created directory: {edf_output_dir}\")\n",
    "            \n",
    "        if not os.path.exists(annotations_output_dir):\n",
    "            os.makedirs(annotations_output_dir)\n",
    "            print(f\"Created directory: {annotations_output_dir}\")\n",
    "            \n",
    "        # Call the function defined in the notebook\n",
    "        generate_edf_and_visbrain_formats(\n",
    "            mouse_ids,\n",
    "            sessions,\n",
    "            recordings,\n",
    "            extra_info,\n",
    "            dataset_type,\n",
    "            base_directory,\n",
    "            sampling_rate\n",
    "        )\n",
    "        \n",
    "        print(\"\\nEDF and Visbrain format generation completed!\")\n",
    "        print(f\"EDF files saved to: {edf_output_dir}\")\n",
    "        print(f\"Visbrain annotations saved to: {annotations_output_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error during EDF and Visbrain format generation: {str(e)}\")\n",
    "else:\n",
    "    print(\"EDF and Visbrain format generation cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c7ac5b",
   "metadata": {},
   "source": [
    "# Path Sheet Generation\n",
    "\n",
    "After generating the EDF and Visbrain format files, the final step is to create a path sheet. This CSV file organizes all your data file paths in one place, making it easier to manage and access the different components of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d6f5b87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: Generate Path Sheet\n",
      "---------------------------\n",
      "Using dataset type: to_score\n",
      "Using base directory: /Volumes/harris/volkan/somnotate-vlkuzun-testing\n",
      "Using sampling rate: 512.0 Hz\n",
      "\n",
      "The path sheet will be saved to: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_sheet.csv\n",
      "Starting path sheet generation...\n",
      "Including ['/Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_manual_annotation/annotations_visbrain_sub-015_ses-01_recording-01_time-0-20h.txt'] in the to_score set.\n",
      "Including ['/Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/edfs/output_sub-015_ses-01_recording-01_time-0-20h.edf'] in the to_score set.\n",
      "output_sub-015_ses-01_recording-01_time-0-20h\n",
      "\n",
      "Path sheet generation completed!\n",
      "Path sheet saved to: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_sheet.csv\n",
      "Starting path sheet generation...\n",
      "Including ['/Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_manual_annotation/annotations_visbrain_sub-015_ses-01_recording-01_time-0-20h.txt'] in the to_score set.\n",
      "Including ['/Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/edfs/output_sub-015_ses-01_recording-01_time-0-20h.edf'] in the to_score set.\n",
      "output_sub-015_ses-01_recording-01_time-0-20h\n",
      "\n",
      "Path sheet generation completed!\n",
      "Path sheet saved to: /Volumes/harris/volkan/somnotate-vlkuzun-testing/to_score_set/to_score_sheet.csv\n"
     ]
    }
   ],
   "source": [
    "# STEP 3: Generate Path Sheet\n",
    "# ---------------------------\n",
    "print(\"STEP 3: Generate Path Sheet\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# Use the parameters collected at the beginning\n",
    "print(f\"Using dataset type: {dataset_type}\")\n",
    "print(f\"Using base directory: {base_directory}\")\n",
    "print(f\"Using sampling rate: {sampling_rate} Hz\")\n",
    "\n",
    "# Show the expected path sheet output location\n",
    "expected_output_path = os.path.join(base_directory, f\"{dataset_type}_set\", f\"{dataset_type}_sheet.csv\")\n",
    "print(f\"\\nThe path sheet will be saved to: {expected_output_path}\")\n",
    "\n",
    "# Confirm before proceeding\n",
    "proceed = input(\"\\nProceed with path sheet generation? (y/n): \").strip().lower()\n",
    "\n",
    "if proceed == 'y':\n",
    "    try:\n",
    "        print(\"Starting path sheet generation...\")\n",
    "        \n",
    "        # Generate the path sheet using the imported function\n",
    "        output_file = make_train_and_test_sheet(dataset_type, base_directory, sampling_rate)\n",
    "        \n",
    "        print(\"\\nPath sheet generation completed!\")\n",
    "        print(f\"Path sheet saved to: {expected_output_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error during path sheet generation: {str(e)}\")\n",
    "else:\n",
    "    print(\"Path sheet generation cancelled.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084d6537",
   "metadata": {},
   "source": [
    "# Pipeline Summary\n",
    "\n",
    "If all steps completed successfully, you should now have:\n",
    "\n",
    "1. CSV files containing the extracted data from your MAT files\n",
    "2. EDF files containing the EEG and EMG signal data for visualization\n",
    "3. Visbrain format annotation files for sleep stage analysis\n",
    "4. A path sheet CSV file organizing all your data file paths\n",
    "\n",
    "The path sheet can be used with other pipeline tools to further process and analyze the data. The EDF and Visbrain files can be used for visualization and manual verification using tools like Visbrain."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "somnotate-vlkuzun",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
